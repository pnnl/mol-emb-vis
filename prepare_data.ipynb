{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create folders\n",
    "import os\n",
    "\n",
    "folders = [r'data',r'data/embeddings',r'data/features',r'data/truth',r'data/relationships',r'data/prepared_data',r'data/prepared_data/UMAPs']\n",
    "\n",
    "for folder in folders:\n",
    "    try:\n",
    "        os.mkdir(folder)\n",
    "        print(\"created \" + folder + \" folder\")\n",
    "    except:\n",
    "        print(folder + \" folder already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import molplotly as molplotly\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "\n",
    "import glob\n",
    "\n",
    "\n",
    "#FILES\n",
    "embedding_files = sorted(glob.glob(r'data/embeddings/*.csv'))\n",
    "feature_files = glob.glob(r'data/features/*.csv')\n",
    "\n",
    "#NAMING AND INDEXING LISTS AND DICTIONARIES\n",
    "model_names = [embedding_files[x][embedding_files[x].rindex('/')+1:embedding_files[x].rindex('.')] for x in range(len(embedding_files))]\n",
    "model_name_index = dict(zip(model_names,list(range(len(model_names)))))\n",
    "model_index_name = dict(zip(list(range(len(model_names))),model_names))\n",
    "\n",
    "#EMBEDDINGS\n",
    "general_model_embeddings = [pd.read_csv(embedding_files[x]) for x in range(len(embedding_files))]\n",
    "\n",
    "#global variables for chosen dataset part 1\n",
    "model_embeddings = general_model_embeddings.copy()\n",
    "models = dict(zip(model_names,model_embeddings))\n",
    "all_molecules = model_embeddings[0]['SMILES'].tolist()\n",
    "molecule_name_index = dict(zip(all_molecules,list(range(len(all_molecules)))))\n",
    "molecule_index_name = dict(zip(list(range(len(all_molecules))),all_molecules))\n",
    "molecules = all_molecules.copy()\n",
    "\n",
    "num_models = len(model_embeddings)\n",
    "num_molecules = len(all_molecules)\n",
    "\n",
    "#MOLECULAR PROPERTIES\n",
    "general_mol_features = pd.read_csv(feature_files[0])\n",
    "\n",
    "#SIMILARITIES\n",
    "general_model_similarities = dict(zip(model_names,[pd.DataFrame(cosine_similarity(model_embeddings[x].set_index('SMILES'),(model_embeddings[x].set_index('SMILES')))).rename(columns=dict(zip(range(3282),all_molecules)),index=dict(zip(range(3282),all_molecules))) for x in range(len(model_embeddings))]))\n",
    "\n",
    "mol_features = general_mol_features.copy()\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numeric_mol_features = mol_features.select_dtypes(include=numerics)\n",
    "numeric_mol_features = numeric_mol_features.loc[:, (numeric_mol_features != 0).any(axis=0)]\n",
    "features = list(numeric_mol_features.columns)\n",
    "features_index = dict(zip(features,list(range(len(features)))))\n",
    "\n",
    "model_similarities = general_model_similarities.copy()\n",
    "\n",
    "print(\"models: \" + str(model_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create UMAPs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "\n",
    "embedding_data = [model_embeddings[x].drop('SMILES',axis=1).values for x in range(num_models)]\n",
    "scaled_data = [StandardScaler().fit_transform(embedding_data[x]) for x in range(num_models)]\n",
    "\n",
    "embeddings = [reducer.fit_transform(scaled_data[x]) for x in range(num_models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_smiles = [pd.DataFrame(embeddings[x]).rename(columns={0:'x',1:'y'}).join(model_embeddings[x].reset_index()['SMILES']) for x in range(num_models)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test scatter plot of UMAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(embedding_smiles[2],x='x',y='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save UMAPs to folder \\data\\prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_models):\n",
    "    embedding_smiles[i].to_csv(r'data/prepared_data/UMAPs/umap_'+model_names[i]+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate pairwise Spearman's rank correlation coefficient dataframe: (may take a few minutes or fourteen minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearman_model_avgs = pd.DataFrame(index=range(num_models),columns=range(num_models))\n",
    "spearman_model_meds = pd.DataFrame(index=range(num_models),columns=range(num_models))\n",
    "pairwise_spearmanr = pd.DataFrame(columns=(['model1','model2']+list(range(num_molecules))))\n",
    "\n",
    "for i in range(num_models):\n",
    "    pairwise_spearmanr.loc[len(pairwise_spearmanr)] = [i,i]+[1]*num_molecules\n",
    "    for k in range(i):\n",
    "        data1 = model_similarities[model_index_name[i]]\n",
    "        data2 = model_similarities[model_index_name[k]]\n",
    "        print(model_index_name[i]+', '+model_index_name[k])\n",
    "\n",
    "        spearman_statistics = pd.DataFrame(index=range(2),columns=range(num_molecules))\n",
    "        for column in range(num_molecules):\n",
    "            spearman_statistics.iloc[:,column] = spearmanr(data1.iloc[:,column],data2.iloc[:,column])\n",
    "        pairwise_spearmanr.loc[len(pairwise_spearmanr)] = [i,k]+spearman_statistics.iloc[0,:].tolist()\n",
    "        pairwise_spearmanr.loc[len(pairwise_spearmanr)] = [k,i]+spearman_statistics.iloc[0,:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save pairwise spearman to folder \\data\\prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_spearmanr.to_csv(r'data/prepared_data/pairwise_spearmanr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate nearest neighbor files: (may also take a few minutes, maybe a long time, like an hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "from random import sample \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "data = [model_embeddings[x].reset_index().iloc[:,1:] for x in range(num_models)]\n",
    "\n",
    "model_count = num_models\n",
    "\n",
    "overlap_func = pd.DataFrame(columns=['num_nbrs','model1','model2','overlap_percent'])\n",
    "\n",
    "for i in range(20):\n",
    "    nbrs = int(0.0004510926*len(all_molecules)*1.5**i)\n",
    "    if nbrs > 1:\n",
    "        model_nbrs = [NearestNeighbors(n_neighbors=nbrs, algorithm='ball_tree').fit(data[x].set_index('SMILES')).kneighbors(data[x].set_index('SMILES')) for x in range(model_count)]\n",
    "        for i in range(model_count):\n",
    "            for k in range(i):\n",
    "                overlap_func.loc[len(overlap_func.index)] = [nbrs, i, k, mean([float(len(set(model_nbrs[i][1][mol][1:]).intersection(set(model_nbrs[k][1][mol][1:]))))/float(nbrs) for mol in range(len(data))])]\n",
    "                print(\"model \" + str(i) + \" v \" + str(k) + \", # neighbors: \" + str(nbrs) + \", avg overlap: \" + str(overlap_func.loc[len(overlap_func.index)-1,'overlap_percent']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save nearest neighbor overlap melted to folder \\data\\prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_func.to_csv(r'data/prepared_data/overlap_func_melted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_func_melted = pd.read_csv(r'data/prepared_data/overlap_func_melted.csv').iloc[:,1:]\n",
    "overlap_func_melted['model1']=[model_index_name[overlap_func_melted.loc[x,'model1']] for x in range(len(overlap_func_melted))]\n",
    "overlap_func_melted['model2']=[model_index_name[overlap_func_melted.loc[x,'model2']] for x in range(len(overlap_func_melted))]\n",
    "overlap_func_melted['model1'] = overlap_func_melted['model1'] + ', ' + overlap_func_melted['model2']\n",
    "overlap_func_melted = overlap_func_melted.drop('model2',axis=1).rename(columns={'model1':'models'})\n",
    "columns = overlap_func_melted['models'].unique()\n",
    "overlap_func_melted = overlap_func_melted.pivot(index='num_nbrs',columns=['models']).droplevel(0,axis=1)\n",
    "overlap_func_melted.index = overlap_func_melted.index.astype(int)\n",
    "overlap_func_melted = overlap_func_melted.loc[:,columns]\n",
    "for name in model_names:\n",
    "    overlap_func_melted.insert(len(overlap_func_melted.iloc[0,:]), str(name + ', ' + name), [1]*len(overlap_func_melted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save nearest neighbor overlap unmelted to folder \\data\\prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_func_melted.to_csv(r'data/prepared_data/overlap_func.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of nearest neighbors to show on UMAP when molecule is clicked, change if desired\n",
    "num_nbrs = 10\n",
    "\n",
    "neighbors = pd.DataFrame(index=range(3282))\n",
    "for i in range(num_models):\n",
    "    nbrs = pd.DataFrame(NearestNeighbors(n_neighbors=num_nbrs, algorithm='ball_tree').fit(model_embeddings[i].iloc[:,:-1]).kneighbors(model_embeddings[i].iloc[:,:-1])[1])\n",
    "    nbrs = nbrs.rename(columns={key: key+10*i for key in list(range(10))})\n",
    "    neighbors = neighbors.join(nbrs)\n",
    "\n",
    "\n",
    "neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save nearest neighbors to folder \\data\\prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors.to_csv(r'data/prepared_data/nearest_neighbors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the molecular features here for the next two files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include only numerical features in correlation calculation\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numeric_mol_features = mol_features.select_dtypes(include=numerics)\n",
    "\n",
    "#       The items below filters out columns to decrease the number of features, use if you have more than 400 features\n",
    "\n",
    "#delete any columns (features) which only include 0s\n",
    "numeric_mol_features = numeric_mol_features.loc[:, (numeric_mol_features != 0).any(axis=0)]\n",
    "\n",
    "#drop all columns with more than the threshhold zeros\n",
    "zero_threshhold = 3000\n",
    "test = numeric_mol_features.copy()\n",
    "drop = []\n",
    "zeroses = []\n",
    "\n",
    "for col in test.columns:\n",
    "    if 0 in list(test.loc[:,col]):\n",
    "        zeros = test.loc[:,col].value_counts()[0]\n",
    "        zeroses.append(zeros)\n",
    "        if zeros > zero_threshhold:\n",
    "            drop.append(col)\n",
    "\n",
    "#view the number of zeros the features\n",
    "px.histogram(zeroses,nbins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run if you wish to drop all columns with more than the threshhold of zeros\n",
    "test = test.drop(drop,axis=1)\n",
    "features = list(test.columns)\n",
    "\n",
    "print(\"number of features used: \" + str(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate correlations between distances between two molecules and differences in their features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the higher the sample of molecules you use, the more accurate the calculated correlations, but the longer it will take\n",
    "sample_size = 2000\n",
    "output_dict = dict(sample(list(molecule_index_name.copy().items()), sample_size))\n",
    "\n",
    "model = pd.DataFrame()\n",
    "model = model_similarities[model_names[0]].copy().loc[list(output_dict.values()),list(output_dict.values())]\n",
    "model.columns = list(output_dict.keys())\n",
    "model = model.melt()\n",
    "model.insert(1,'variable2',model.index % sample_size)\n",
    "model['variable2'] = list(map(lambda x: list(output_dict.keys())[x],model['variable2']))\n",
    "\n",
    "model = model.rename(columns={\"value\":model_names[0]})\n",
    "for i in range(1,num_models):\n",
    "    model.insert(len(model.iloc[0,:]),model_names[i],model_similarities[model_names[i]].copy().loc[list(output_dict.values()),list(output_dict.values())].melt().iloc[:,[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w_features = model.copy()\n",
    "for i in range(len(features)):\n",
    "    model_w_features['∆' + features[i]] = abs(pd.DataFrame(mol_features.loc[model['variable'],features[i]]).reset_index().loc[:,features[i]] - pd.DataFrame(mol_features.loc[model['variable2'],features[i]]).reset_index().loc[:,features[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = pd.DataFrame(index=model_names,columns=['∆' + item for item in features])\n",
    "for i in model_names:\n",
    "    print(i)\n",
    "    for k in features:\n",
    "        corrs.loc[i,'∆' + k] = model_w_features.loc[:,i].corr(model_w_features.loc[:,'∆' + k])\n",
    "\n",
    "corrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save property correlations to folder \\data\\prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs.to_csv(r'data/prepared_data/property_correlations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate R^2 scores from ML predictions on molecular features from embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features used will be the same as features used to calculate correlations from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "\n",
    "scores = pd.DataFrame(columns=model_names)\n",
    "times = pd.DataFrame(columns=model_names)\n",
    "\n",
    "# sample_size = 200\n",
    "# molecules = sample((all_molecules.copy()),sample_size)\n",
    "molecules = all_molecules.copy()\n",
    "\n",
    "properties = features.copy()\n",
    "\n",
    "for prop in properties:\n",
    "    for i in model_names:\n",
    "        then = time.time()\n",
    "        X = models[i].set_index('SMILES').loc[molecules,:]\n",
    "        y = mol_features.set_index('SMILES').loc[molecules,prop]\n",
    "\n",
    "        train_X,val_X,train_y,val_y = train_test_split(X,y,random_state=1)\n",
    "\n",
    "        model = linear_model.OrthogonalMatchingPursuit()\n",
    "        model.fit(train_X, train_y)\n",
    "        melb_preds = model.predict(val_X)\n",
    "        scores.loc[prop,i] = float(r2_score(val_y, melb_preds))\n",
    "        print(prop + ', ' + i + ', ' + 'r2: ' + str(r2_score(val_y, melb_preds)))\n",
    "        now = time.time()\n",
    "        times.loc[prop,i] = now - then\n",
    "\n",
    "\n",
    "scores.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(scores[scores>0].astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save property predictions r2 scores to folder \\data\\prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv(r'data/prepared_data/property_predictions_r2_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
